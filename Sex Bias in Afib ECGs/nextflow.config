// General configuration used in all profiles
manifest {
  description = 'BAIHA Proof of Concept AFib Benchmark Workflow : Model Output' 
  author = 'Claire Furtick'
  nextflowVersion = '>=19.10.0'
  version = '1.0.8'
}

// Profiles configure nextflow depending on the environment (local, integration, live, etc.)

profiles {

	  docker {
      process {
          withName: dataset_validation{
            container = "docker.io/clairefurtick/baiha_dataset_validation:v3"
          }
      }
      process {
          withName: dataset_compute_metrics{
            container = "docker.io/clairefurtick/baiha_dataset_metrics:v3"
          }
      }
      process {
          withName: dataset_consolidation{
            container = "docker.io/clairefurtick/baiha_dataset_consolidation:v1"
          }
      }
      process {
          withName: output_validation{
            container = "docker.io/clairefurtick/baiha_output_validation:v1"
          }
      }
      process {
          withName: output_compute_metrics{
            container = "docker.io/clairefurtick/baiha_output_metrics:v1"
          }
      } 
      process {
          withName: output_consolidation{
            container = "docker.io/clairefurtick/baiha_output_consolidation:v1"
          }
      }

      docker.enabled = true
      // set time zone for running docker containers
      //docker.runOptions = '--user \$(id -u):\$(id -g) -e TZ="\$([ -z \\"\$TZ\\"] && cat /etc/timezone || echo \\"\$TZ\\")"'
      docker.runOptions = '--user \$(id -u):\$(id -g) -e TZ=Europe/Madrid'
  }
}

// default parameter values

params  {

  // Boolean operator: if set to CLOSED the whole workflow is executed; if OPEN, metrics are computed but aggregation/consolidation is not performed
  challenge_status = "CLOSED"

  participant_id = "Nuubo"
  community_id = "BAIHA"
  data_dir = "$baseDir/BAIHA_test_data"
  test_run_dir = "${params.data_dir}/test_run"
  //challenges_ids  = "model_output"
  //input = "${params.data_dir}/input_data/${params.participant_id}_output.csv"
  challenges_ids  = "training_dataset"
  input = "${params.data_dir}/input_data/${params.participant_id}_dataset.csv"
  goldstandard_dir = "${params.data_dir}/gold_standard/key.csv"
  assess_dir = "${data_dir}/other_participant_data"
  outdir = "${params.test_run_dir}/results"
  validation_result = "${params.test_run_dir}/${participant_id}_validation.json"
  assessment_results = "${params.test_run_dir}/${participant_id}_metrics_output"
  data_model_export_dir = "${params.test_run_dir}/consolidation_results.json"
  statsdir = "${params.test_run_dir}/stats"
  otherdir = "${params.data_dir}/other_dir"
  offline = 1

}

// By default output execution reports
timeline {
  enabled = true
  file = "${params.statsdir}/timeline.html"
  overwrite = true
}
report {
  enabled = true
  file = "${params.statsdir}/report.html"
  overwrite = true
}
trace {
  enabled = true
  file = "${params.statsdir}/trace.txt"
  overwrite = true
}
dag {
  enabled = true
  file = "${params.statsdir}/DAG.dot"
  overwrite = true
}