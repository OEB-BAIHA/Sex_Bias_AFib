/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core/guidance Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

    // MANIFEST

    manifest {
        description     = 'BAIHA Proof of Concept AFib Benchmark Workflow : Training Dataset' 
        author          = 'Claire Furtick'
        homePage        = 'https://github.com/OEB-BAIHA/Sex_Bias_AFib/'
        description     = ""
        nextflowVersion = '>=19.10.0'
        version = '1.0.8'
    }


    // DEFAULT PARAMMETERS VALUES

    params  {

        // Nextflow paths 

            projectDir            = "."
            workDir               = "${params.projectDir}/work"

        // Input Defaults OpenEBench

            // Submitted file
            input                 = "./inputs_dataset/Nuubo_dataset.csv"

            // reference file dir to validate input data
            public_ref_dir        = "./public_reference/baiha_sex_bias_AF_detection"
            
            // name of dataset cohort
            participant_id        = "DEF_PARTICIPANT"  // "Nuubo"

            // directory where the 'gold standards' are found
            goldstandard_dir      = "./metrics_reference/baiha_sex_bias_AF_detection"

            // dataset types for which the benchmark has to be performed [ training_output / model_output ]
            challenges_ids         = "DEF_CHALLENGE"

            // directory where benchmarking data is found
            assess_dir            = "./aggreggation/baiha_sex_bias_AF_detection"
            
            //name or OEB permanent ID for the benchmarking community
            community_id          = "BAIHA"


        // Output Defaults OpenEBench

            // Results
            outdir                = "./results"

            // Workflow executions reports
            statsdir              = "./nf_stats"

            // Plots 
            otherdir              = "./other_files"

            // Input validation
            validation_result     = "${participant_id}_${challenges_ids}_validation.json"

            // Metrics of input
            assessment_results    = "${participant_id}_${challenges_ids}_assessment.json"
            
            // Aggregation of reults
            data_model_export_dir = "${participant_id}_${challenges_ids}_consolidation.json"


        // Boolean operators

            // Decide if aggregation/consolidation is executed [ CLOSED / OPEN ]; cLOSED: executed, OPEN: not executed
            challenge_status      = "CLOSED"
            
            //
            offline               = 1

            // Show helps messages
            help                  = false


        // Container selection

            // training_dataset
            validation_docker_training     = "mmoralesmar/baiha_training_dataset_validation:latest"
            metrics_docker_training        = "mmoralesmar/baiha_training_dataset_metrics:latest"
            consolidation_docker_training  = "mmoralesmar/baiha_training_dataset_consolidation:latest"

            // model_output
            validation_docker_model        = "mmoralesmar/baiha_model_output_validation:latest"
            metrics_docker_model           = "mmoralesmar/baiha_model_output_metrics:latest"
            consolidation_docker_model     = "mmoralesmar/baiha_model_output_consolidation:latest"

    }


    // PROFILES
        
    profiles {

        debug {
            dumpHashes             = true
            process.beforeScript   = 'echo $HOSTNAME'
            cleanup                = false
            nextflow.enable.configProcessNamesValidation = true
        }

        docker { 
            docker.enabled         = true 
            docker.runOptions      = '--user \$(id -u):\$(id -g) -e TZ=Europe/Madrid'
        }

    }


    // DEFAULT EXECUTION REPORTS

    def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
    timeline {
        enabled   = true
        overwrite = true
        file      = "${params.statsdir}/timeline.html"
    }
    report {
        enabled   = true
        overwrite = true
        file      = "${params.statsdir}/report.html"
    }
    trace {
        enabled   = true
        overwrite = true
        file      = "${params.statsdir}/trace.txt"
    }
    dag {
        enabled   = true
        overwrite = true
        file      = "${params.statsdir}/DAG.dot"
    }



    // EXTRA CONF FILES

        // Load modules.config for DSL2 module specific options
        includeConfig 'conf/modules.config'

        